%!TEX root = ../thesis.tex
% ******************************* Thesis Appendix D ****************************
\cleardoublepage
\chapter{Uncertainty quantification practice with \ot}
\label{apx:D}
%*******************************************************************************


\elias{Add short introduction to the motivation}

\elias{Should I print the results?}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{otexample}[\href{https://github.com/efekhari27/thesis/blob/main/numerical_experiments/chapter1/copulas.ipynb}{Bivariate distribution}]
    The following Python code proposes a minimalistic \ot example of a probabilistic uncertainty modeling. 
    \lstset{style=mystyle, language=python}
%
\begin{lstlisting}
    #!/usr/bin/python3
    import openturns as ot
    # Build multivariate distribution from marginals and copula
    copula=ot.GumbelCopula(2.0)
    marginals=[ot.Uniform(1.0, 2.0), ot.Normal(2.0, 3.0)]
    distribution=ot.ComposedDistribution(marginals, copula)
    # Compute first moments
    mean_vector=distribution.getMean()
    covariance_matrix=distribution.getCovariance()
    # Compute CDF (respectively PDF)
    x_cdf=distribution.computeCDF([1.5, 2.5])# x=[1.5, 2.5]
    a_quantile=distribution.computeQuantile([0.9])# alpha=0.9
\end{lstlisting}
%
\end{otexample}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{otexample}[\href{https://github.com/efekhari27/thesis/blob/main/numerical_experiments/chapter1/integration.ipynb}{Numerical integration}]
    The following Python code presents a minimalistic \ot example to build multivariate quadrature rules.
%
\lstset{style=mystyle, language=python}
\begin{lstlisting}
    #!/usr/bin/python3
    import openturns as ot
    marginals=[ot.Exponential(1.0), ot.Uniform(-1.0, 1.0)]
    distribution=ot.ComposedDistribution(marginals)
    # Build a 2D Gaussian quadrature
    n_marginal=[4, 4] # Number of nodes per marginal
    g_quad=ot.GaussProductExperiment(distribution, n_marginal)
    g_nodes, weights=g_quad.generateWithWeights()
    # Build a Monte Carlo design
    n=16 
    mc_nodes=distribution.getSample(n)
    # Build a quasi-Monte Carlo design
    sequence=ot.HaltonSequence(2) # d=2
    qmc_experiment=ot.LowDiscrepancyExperiment(sequence, distribution, n)
    qmc_nodes=qmc_experiment.generate()
\end{lstlisting}
%
\end{otexample}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{otexample}[\href{https://github.com/efekhari27/thesis/blob/main/numerical_experiments/chapter1/designofexperiments.ipynb}{Design of experiments}]
    The following Python code is a minimalistic \ot example to build an LHS and 
    an LHS optimized w.r.t. to a space-filling metric (here the L2-centered discrepancy) using the simulated annealing algorithm. 
    \lstset{style=mystyle, language=python}
%
\begin{lstlisting}
    #!/usr/bin/python3
    import openturns as ot
    marginals=[ot.Uniform(0.0, 1.0), ot.Uniform(0.0, 1.0)]
    distribution=ot.ComposedDistribution(marginals)
    # Build a LHS
    n=10
    LHS_exp=ot.LHSExperiment(distribution, n)
    LHS_design=LHS_exp.generate()
    # Build an optimized LHS using L2-centered discrepancy
    LHS_exp=ot.LHSExperiment(distribution, n)
    SF_metric=ot.SpaceFillingC2()
    SA_profile=ot.GeometricProfile(10., 0.95, 20000)
    LHS_opt=ot.SimulatedAnnealingLHS(LHS_exp, SF_metric, SA_profile)
    LHS_opt.generate()
    LHS_design=LHS_opt.getResult().getOptimalDesign()
\end{lstlisting}
%
\end{otexample}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{otexample}[\href{https://github.com/efekhari27/thesis/blob/main/numerical_experiments/chapter1/reliability.ipynb}{Rare event estimation}]
    The following Python code proposes a minimalistic \ot implementation of rare event estimation algorithms. 
    \lstset{style=mystyle, language=python}
%
\begin{lstlisting}
    #!/usr/bin/python3
    import openturns as ot
    marginals=[ot.Normal(0.0, 1.0), ot.Exponential(1.0)]
    distribution=ot.ComposedDistribution(marginals)
    # Build a limit-state function and failure event
    g=ot.SymbolicFunction(["x1", "x2"], ["(x1 - x2) ^ 2"])
    X=ot.RandomVector(distribution)
    Y=ot.CompositeRandomVector(g, X)
    th=0.0
    failure_event=ot.ThresholdEvent(Y, ot.LessOrEqual(), th)
    # Estimate pf using FORM
    starting_p=distribution.getMean()
    FORM_algo=ot.FORM(ot.Cobyla(), failure_event, starting_p)
    FORM_algo.run()
    FORM_results=FORM_algo.getResult()
    design_point=FORM_results.getStandardSpaceDesignPoint()
    FORM_pf=FORM_results.getEventProbability()
    # Estimate pf using Monte Carlo 
    MC_exp=ot.MonteCarloExperiment()
    MC_algo=ot.ProbabilitySimulationAlgorithm(failure_event, MC_exp)
    MC_algo.run()
    MC_results=MC_algo.getResult()
    MC_pf=MC_results.getProbabilityEstimate()
    MC_pf_confidence=MC_results.getConfidenceLength(0.95)
    # Estimate pf using importance sampling
    aux_distribution=ot.Normal(design_point, [1.0, 1.0])
    standard_event=ot.StandardEvent(failure_event)
    IS_exp=ot.ImportanceSamplingExperiment(aux_distribution)
    IS_algo=ot.ProbabilitySimulationAlgorithm(standard_event, IS_exp)
    IS_algo.run()
    IS_results=IS_algo.getResult()
    IS_pf=IS_results.getProbabilityEstimate()
    IS_pf_confidence=IS_results.getConfidenceLength(0.95)
    # Estimate pf using subset sampling
    SS_algo=ot.SubsetSampling(failure_event)
    SS_algo.run()
    SS_results=SS_algo.getResult()
    SS_pf=SS_results.getProbabilityEstimate()
    SS_pf_confidence=SS_results.getConfidenceLength(0.95)
\end{lstlisting}
%
\end{otexample}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{otexample}[\href{https://github.com/efekhari27/thesis/blob/main/numerical_experiments/chapter1/sensitivity_analysis.ipynb}{Sobol' indices}]
    The following Python code gives a minimalistic \ot implementation of the Sobol' indices to assess global sensitivity analysis on the Ishigami analytical problem. 
    \lstset{style=mystyle, language=python}
%
\begin{lstlisting}
    #!/usr/bin/python3
    import openturns as ot
    g=ot.SymbolicFunction(
        ['x1', 'x2', 'x3'], 
        ['sin(x1) + 7.0 * sin(x2)^2 + 0.1 * x3^4 * sin(x1)']
        )
    X=ot.ComposedDistribution([ot.Uniform(-3.14, 3.14)] * 3)
    size=1000
    # Generate samples and evaluate their images
    sie=ot.SobolIndicesExperiment(im.distributionX, size)
    input_design=sie.generate()
    output_design=im.model(input_design)
    # Four estimators : Saltelli, Martinez, Jansen, and Mauntz-Kucherenko
    SA=ot.JansenSensitivityAlgorithm(input_design, output_design, size)
    sobol_first_order=SA.getFirstOrderIndices()
    sobol_tolal=SA.getTotalOrderIndices()
\end{lstlisting}
%
\end{otexample}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{otexample}[\href{https://github.com/efekhari27/thesis/blob/main/numerical_experiments/chapter1/surrogates.ipynb}{Gaussian process regression}]
    The following Python code gives a minimalistic \ot implementation of an ordinary kriging model fitting. 
    \lstset{style=mystyle, language=python}
%
\begin{lstlisting}
    #!/usr/bin/python3
    import openturns as ot
    g=ot.SymbolicFunction(['x'], ['x * sin(x) + sin(6 * x)'])
    x_train=ot.Uniform(0., 12.).getSample(7) # n=7
    y_train=g(x_train)
    basis=ot.ConstantBasisFactory(1).build() # d=1
    cov_model=ot.MaternModel([1.], 1.5)
    algo=ot.KrigingAlgorithm(x_train,y_train,cov_model,basis)
    algo.run()
    kriging_results=algo.getResult()
    kriging_predictor=kriging_results.getMetaModel()
\end{lstlisting}
%
\end{otexample}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%